\documentclass[twocolumn,12pt,a4paper]{article}
\usepackage[latin1]{inputenc}
\usepackage[T1]{fontenc} 
\usepackage[francais, english]{babel} 

\pagestyle{empty} 


\usepackage{amsmath, amsthm}
\newtheorem{theorem}{Theorem}
\newtheorem{proposition}{Proposition}
\newtheorem{lemma}{Lemma}
\newtheorem*{proof*}{Proof}
\newtheorem{definition}{Definition}

\newtheorem{exercise}{Exercise}
\newtheorem{question}{Question}

\newtheorem{example}{Example}

\newtheorem{remark}{Remark}

\usepackage[a4paper,left=.8cm, right=.8cm,top=1.5cm,bottom=1.5cm]{geometry}
\setlength{\columnsep}{1.2cm}

\usepackage{cancel}
\usepackage{bm}
\usepackage{amssymb,amsfonts}
\usepackage{mathrsfs}
\usepackage{color}
%\usepackage{hyperref}
\usepackage{dsfont}
\usepackage{graphicx}
\usepackage{algorithmicx}
\usepackage[ruled]{algorithm}
\usepackage{algpseudocode}
\usepackage{marginnote}
\newcommand{\Ptr}{\mathcal P^{\rm tr}}
\newcommand{\tr}{{\rm tr}}
\newcommand{\N}{\mathbb N}
\newcommand{\calN}{\mathcal N}
\newcommand{\bP}{\bold P}
\newcommand{\calK}{\mathcal K}
\newcommand{\calF}{\mathcal F}
\newcommand{\calH}{\mathcal H}
\newcommand{\calP}{\mathcal P}
\newcommand{\calC}{\mathcal C}
\newcommand\red[1]{\textcolor{red} {#1} }
\newcommand{\R}{\mathbb R}
\newcommand{\bX}{\bar X}
\newcommand{\Ktr}{\calK^{\rm tr}}
\title{ \bfseries \Huge {Handout 1: RVs - Inequalities - Limit theorems }}    
\vspace{-4cm}        

\date{Due date : February $3^{rd}$}       
\vspace{-4cm}        
\newcounter{num}  % Create a new counter for paragraphs
\begin{document}
	\maketitle
\setcounter{num}{1}  % Start the paragraph counter at 1

\thispagestyle{empty} 
	\paragraph{Brief recap}
	\begin{enumerate}
		\item PMFs are usually more intuitive to retrieve for discrete rvs, whereas CDFs are more intuitive for continuous rvs.
		\item A PMF is valid iif, $p(e)\geq 0$ for any event, and $\sum_{i\in E} = 1$, where $E$ is the sample space.
		\item A PDFs $f$ is valid iif : $f\geq 0$ for any event, $f$ is piecewise continuous, and $\int_{-\infty}^\infty f(x)dx = 1$.
		\item A ${\rm Bern}(p)$ r.v. is the indicator of success in a Bernoulli trial with probability of success $p$.
		\item A ${\rm Bin}(n, p)$ r.v. is the number of successes in $n$ independent Bernoulli trials, all with the same probability $p$ of success.
		\item Cauchy-Schwarz and Jensen inequalities give bounds on expectations. 
		Markov and Chebyshev inequalities give bounds
		on tail probabilities.
		\item The LLN and the CLT describe the behavior of the sample mean $\bar{X}_n$ of i.i.d. rvs $X_1, X_2, \dots$ with mean $\mu$ and variance $\sigma^2$. The LLN says that $P(\underset{n\rightarrow\infty}{\rm lim}\bar{X}_n = \mu$ with probability 1. 
		The CLT says that 
		$$
		\sqrt{n} \left( \frac{\bar{X}_n - \mu}{\sigma} \right) \rightarrow \calN(0, 1)
		$$
		in distribution, which can be recast as
		$$
		\bar{X}_n \sim \calN\left(\mu, \frac{\sigma^2}{n}\right).
		$$
	\end{enumerate}
	\paragraph{Exercise \thenum.}
	Consider a sequence of independent Bernoulli trials, each with the same success probability $p \in ]0, 1[$, with trials performed until a success occurs. Let $X$ be the number of failures before the first successful trial. 
	\begin{enumerate}
		\item Determine $P (X = k)$ and show that it is a valid PMF.
		\item Calculate $E[X]$ and $V[X]$.
	\end{enumerate}
	This is the geometric distribution $X\sim {\rm Geom}(p)$.
	\stepcounter{num} 
	\paragraph{Exercise \thenum.}
	\begin{enumerate}
		\item Show that $p(n) = ( 1/2)^{n+1}$ for $n = 0, 1, 2,\ldots$ is a valid PMF for a discrete r.v.
		\item  Find the CDF of a random variable with the PMF in 1.
	\end{enumerate}
	
	\stepcounter{num} 
	\paragraph{Exercise \thenum.}
	\begin{enumerate}
		\item Benford's law states that in a very large variety of real-life data sets, the first digit approximately follows a particular distribution with about a 30\% chance of a 1, an 18\% chance of a 2, and in general
		$$
		P(D = j) = {\rm log}_{10}\left(\frac{j+1}{j}\right),\quad  1\leq j\leq 9.
		$$ 
		where $D$ is the first digit of a randomly chosen element. Check that this is a valid PMF.
	\end{enumerate}
	
	
	\stepcounter{num} 
	\paragraph{Exercise \thenum.}
	There are $n$ eggs, each of which hatches a chick with probability $p$ (independently).
	Each of these chicks survives with probability $r$, independently. \begin{enumerate}
		\item What is the distribution of the number of chicks that hatch? 
	\item What is the distribution of the number of chicks that
	survive? 
	\end{enumerate}
	Give the PMFs; also give the names of the distributions and their parameters, if applicable.
	
	\stepcounter{num} 
	\paragraph{Exercise \thenum.}
	Let $X \sim {\rm Bin}(n, p)$ and $Y \sim {\rm Bin}(m, p)$, independent of $X$.
	\begin{enumerate}
		\item  Show that $X+Y$ is Binomial and give its distribution.
	\item  Is $X-Y$ Binomial? If yes, give its distribution. If not, why?
	\end{enumerate}
	
	\stepcounter{num} 
	\paragraph{Exercise \thenum.}
	There are two coins, one with probability $p_1$ of Heads and the other with probability $p_2$ of Heads. 
	One of the coins is randomly chosen (with equal probabilities for the two coins). 
	It is then flipped $n \geq 2$ times. 
	Let X be the number of times it lands Heads.
	\begin{enumerate}
		\item Find the PMF of $X$.
		\item What is the distribution of $X$ if $p_1 = p_2$?
		\end{enumerate}
	
	
	
	\stepcounter{num} 
	\paragraph{Exercise \thenum.}
	Student A flips a fair coin \(n\) times and student B flips another fair coin \(n+1\) times, resulting in independent random variables \( X \sim \text{Bin}(n, \frac{1}{2}) \) and \( Y \sim \text{Bin}(n+1, \frac{1}{2}) \).
	
	
	\begin{enumerate}
		\item Show that \( P(X < Y) = 1- P(n - X < n + 1 - Y) \).
	
	\item Compute \( P(X < Y) \).
	\end{enumerate}
	
	
	
	\stepcounter{num} 
	\paragraph{Exercise \thenum.}
	Prove that $E[X]^2\leq E[X^2]$. %Chauchy-Schwarz
	
	
	\stepcounter{num} 
	\paragraph{Exercise \thenum.}
	For a non-negative rv $X$ and $a\in\R_+^*$ 
	\begin{enumerate}
		\item Show that a $\mathbb I _{|X|\geq a} \leq X$ ($\mathbb I $ is the indicator rv).
		\item Prove the Markov inequality using 1.
	\end{enumerate}
	
		\stepcounter{num} 
	\paragraph{Exercise \thenum.}
	Let \( X \) be the number of purchases you will make on the website of a company in a specified time period. Let the PMF of \( X \) be
	
	\[
	P(X = k) = \frac{e^{-\lambda} \lambda^k}{k!}, \quad k = 0, 1, 2, \dots
	\]
	
	This distribution is called the Poisson distribution with parameter \( \lambda \), and it will be studied extensively in later chapters.
	\begin{enumerate}
		\item Find \( P(X \geq 1) \) and \( P(X \geq 2) \). %using 2 different methods.
		
		\item Find the conditional PMF of \( X \) given \( X \geq 1 \). (This conditional distribution is called a truncated Poisson distribution.)
	\end{enumerate}
	
	
	\stepcounter{num} 
	\paragraph{Exercise \thenum.}
	In a national survey, a random sample of people are chosen and asked whether they support a certain policy. 
	Assume that everyone in the population is equally likely to
	be surveyed at each step, and that the sampling is with replacement.
	Let $n$ be the sample size, and let $\hat p$ and $p$ be the proportion of people who support the policy in the sample
	and in the entire population, respectively. 
	Show that
	\begin{equation}
		\forall c>0, \quad P(|\hat p - p|>c) \leq \frac{1}{4nc^2}.
	\end{equation}
	
	\stepcounter{num} 
	\paragraph{Exercise \thenum.}
	For i.i.d. r.v.s $X_1,\ldots , X_n$ with mean $\mu$ and variance $\sigma^2$, give a value of $n$ that will ensure that there is at least a 99\% chance that the sample mean will
	be within 2 standard deviations of the true mean $\mu$.
	
	
	\stepcounter{num} 
	\paragraph{Exercise \thenum.}
	Let $X_1, X_2,\ldots$ be i.i.d. positive random variables with mean 2. 
	Let $Y_1, Y_2,\ldots$ be i.i.d. positive random variables with mean 3. 
	\begin{enumerate}
		\item Show that
		$$
		\frac{X_1+X_2+\ldots+X_n}{Y_1+Y_2+\ldots+Y_n}\underset{n\rightarrow\infty}{\rightarrow} \frac{2}{3}
		$$
		with probability 1. 
		Does it matter whether the $X_i$ are independent of the $Y_j$ ?
	\end{enumerate}
	
	\stepcounter{num} 
	\paragraph{Exercise \thenum.}
	Let $Y_1, Y_2,\ldots, U_{100}$ be i.i.d. r.v.s with distribution  ${\rm Unif}(0,1)$ and $X = Y_1 + Y_2 + \ldots + U_{100}$.
	\begin{enumerate}
		\item Which important distribution is the distribution of X very close to? Specify what
		the parameters are, and state which theorem justifies your choice.
		\item Give a simple but accurate approximation for $P(X > 17)$. Justify briefly.
	\end{enumerate}
	
	
	\stepcounter{num} 
	\paragraph{Exercise \thenum.}
Let $Y \sim \text{Bin}(n, p)$, with $n\in\mathbb N^*$ and $p\in[0,1]$. 
Show that 
$$
 Y\underset{n\rightarrow\infty}{\sim}\calN\left(np, np(1 - p)\right).
$$	


\stepcounter{num} 
\paragraph{Exercise \thenum.}
	\begin{enumerate}
	\item Let $Y = e^X$, with $X \sim \text{Expo}(3)$. Find the mean and variance of $Y$.
\item For $Y_1, \dots, Y_n$ i.i.d. with the same distribution as $Y$ from the previous question, what is the approximate distribution of the sample mean $\bar{Y}_n = \frac{1}{n} \sum_{j=1}^{n} Y_j$ when $n$ is large?
	\end{enumerate}


	\paragraph{References:} Introduction to probability (Blitzstein and Huang), Stochastic Processes (Gallager).
\end{document}